"""
Disk Persistence Layer for FUSE.
Implements streaming writes, single-level sharding, and lazy LRU eviction.
"""

import hashlib
import logging
import os
import shutil
import time
from heapq import heappop, heappush
from typing import AsyncGenerator

import trio

logger = logging.getLogger(__name__)


def clear_cache(cache_dir: str):
    """Removes *.tmp and *.bin files from cache_dir recursively"""
    logging.info("Clearing cache...")
    for root, _, files in os.walk(cache_dir):
        for f in files:
            path = os.path.join(root, f)
            if path.endswith(".tmp") or path.endswith(".bin"):
                os.unlink(path)


class DiskPersistence:
    def __init__(self, cache_dir: str, max_size_gb: int = 2048, max_age_days: int = 7):
        self.cache_dir = cache_dir
        self.max_size_bytes = float(max_size_gb) * 1024**3
        self.max_age_seconds = max_age_days * 86400
        self.start_time = time.time()

        self.current_size = 0
        self.lock = trio.Lock()
        self.access_log = []  # Heap: (timestamp, path, size)
        self.access_map = {}  # Map: {path: latest_timestamp}

    async def run_services(self, nursery):
        """Starts background maintenance and discovery."""
        nursery.start_soon(self._graceful_init)
        nursery.start_soon(self._background_maintenance)

    def _get_chunk_path(self, fs_path: str, chunk_index: int, mtime: float) -> str:
        """Determines path with 256-shard distribution based on chunk key."""
        sha256_hash = hashlib.sha256(fs_path.encode("utf-8")).hexdigest()
        shard1 = sha256_hash[:2]
        shard2 = f"{(chunk_index // 1000):07d}"  # Secondary shard to prevent too many files in one dir
        shard_dir = os.path.join(self.cache_dir, shard1, shard2)
        os.makedirs(shard_dir, exist_ok=True)
        mtime_ms = int(mtime * 1000)
        return os.path.join(
            shard_dir, f"{sha256_hash}_{mtime_ms}_{chunk_index:07d}.bin"
        )

    async def _graceful_init(self):
        """Non-blocking cache discovery."""
        logger.info("Starting graceful cache discovery...")
        await trio.to_thread.run_sync(self._sync_scan)
        logger.info(f"Discovery complete. Initial size: {self.current_size/1e9:.2f} GB")

    def _sync_scan(self):
        """Synchronous recursive walk to rebuild state."""
        for root, _, files in os.walk(self.cache_dir):
            for f in files:
                path = os.path.join(root, f)
                try:
                    stat = os.stat(path)

                    if f.endswith(".tmp"):
                        if stat.st_mtime < self.start_time:
                            os.remove(path)
                        continue

                    self.current_size += stat.st_size
                    self.access_map[path] = stat.st_atime
                    heappush(self.access_log, (stat.st_atime, path, stat.st_size))
                except OSError:
                    continue

    async def retrieve_chunk(
        self, fs_path: str, chunk_index: int, mtime: float
    ) -> bytes | None:
        """
        Retrieves a chunk from disk.
        Updates LRU access time BEFORE reading to prevent concurrent eviction.
        """
        path = self._get_chunk_path(fs_path, chunk_index, mtime)

        # 1. OPTIMISTIC PROMOTION (Pinning)
        # Mark as accessed so GC doesn't delete it while we read.
        # Double-check pattern is not strictly needed here for safety,
        # but the lock is needed to update the map safely.
        async with self.lock:
            if path in self.access_map:
                self.access_map[path] = time.time()

        try:
            # 2. READ (Safe now)
            data = await trio.to_thread.run_sync(self._read_file, path)

            # 3. SELF-HEALING
            # If file exists but wasn't in map (race condition or init miss)
            if path not in self.access_map:
                async with self.lock:
                    if path not in self.access_map:
                        self.current_size += len(data)
                        now = time.time()
                        self.access_map[path] = now
                        heappush(self.access_log, (now, path, len(data)))

            return data

        except FileNotFoundError:
            return None

    def _read_file(self, path: str) -> bytes:
        with open(path, "rb") as f:
            return f.read()

    async def store_chunk_from_stream(
        self,
        fs_path: str,
        chunk_index: int,
        mtime: float,
        stream: AsyncGenerator[bytes, None],
    ):
        """Consumes a stream and writes it to disk. Returns the bytes written."""
        path = self._get_chunk_path(fs_path, chunk_index, mtime)
        temp_path = f"{path}.{os.getpid()}.tmp"
        result = bytearray()
        bytes_written = 0
        try:
            # Write to .tmp (No lock needed)
            async with await trio.open_file(temp_path, "wb") as f:
                async for chunk in stream:
                    await f.write(chunk)
                    bytes_written += len(chunk)
                    result.extend(chunk)

            # Atomic Rename (No lock needed)
            await trio.to_thread.run_sync(os.rename, temp_path, path)

            # 1. EVICT (Manages Lock Internally)
            await self.evict(bytes_written)

            # 2. UPDATE METADATA (Acquire Lock)
            async with self.lock:
                # If overwriting, logic could go here to subtract old size
                self.current_size += bytes_written
                now = time.time()
                self.access_map[path] = now
                heappush(self.access_log, (now, path, bytes_written))
            return bytes(result)
        except Exception as e:
            if os.path.exists(temp_path):
                await trio.to_thread.run_sync(os.remove, temp_path)
            raise e

    async def evict(self, required_space: int):
        """
        Free up space removing old items.
        THREAD-SAFE: Uses lock for state, releases for I/O.
        """
        while True:
            # 1. DECISION PHASE (Lock Held)
            async with self.lock:
                if self.current_size + required_space <= self.max_size_bytes:
                    return

                if not self.access_log:
                    return

                ts_log, path, size = heappop(self.access_log)

                if path not in self.access_map:
                    continue

                # Lazy check: if map has newer timestamp, repush
                if self.access_map[path] > ts_log:
                    heappush(self.access_log, (self.access_map[path], path, size))
                    continue

                # Remove from index immediately
                del self.access_map[path]
                self.current_size -= size

            # 2. I/O PHASE (Lock Released)
            try:
                await trio.to_thread.run_sync(os.remove, path)
                logger.debug(f"Evicted: {path}")
            except OSError:
                pass

    async def _background_maintenance(self):
        """
        Hourly cleanup. Uses snapshot approach to avoid blocking.
        """
        while True:
            await trio.sleep(3600)
            now = time.time()

            # 1. Fast Snapshot (Lock Held)
            async with self.lock:
                try:
                    usage = await trio.to_thread.run_sync(
                        shutil.disk_usage, self.cache_dir
                    )
                    disk_critical = (usage.free / usage.total) < 0.05
                except OSError:
                    disk_critical = False  # Disk might be unmounted or weird error

                expired_candidates = [
                    path
                    for path, ts in self.access_map.items()
                    if (now - ts > self.max_age_seconds) or disk_critical
                ]

            # 2. Slow Deletion (Lock Released)
            for path in expired_candidates:
                await trio.sleep(0)  # Cooperative yield

                try:
                    stat = await trio.to_thread.run_sync(os.stat, path)
                    await trio.to_thread.run_sync(os.remove, path)

                    # 3. State Update (Lock Held)
                    async with self.lock:
                        if path not in self.access_map:
                            continue

                        del self.access_map[path]
                        self.current_size -= stat.st_size
                except OSError:
                    pass
